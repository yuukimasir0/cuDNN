### cuDNNハンドル

cuDNNライブラリはホストAPIを公開していますが、GPUを使用する操作のために必要なデータがデバイスから直接アクセス可能であることを前提としています。

cuDNNを使用するアプリケーションは、`cudnnCreate()`を呼び出してライブラリコンテキストへのハンドルを初期化する必要があります。このハンドルは、GPUデータを操作するすべての後続のライブラリ関数に明示的に渡されます。アプリケーションがcuDNNの使用を終了するときは、`cudnnDestroy()`を使用してライブラリハンドルに関連するリソースを解放できます。このアプローチにより、複数のホストスレッド、GPU、およびCUDAストリームを使用する場合に、ユーザーはライブラリの動作を明示的に制御できます。

例えば、アプリケーションはcuDNNハンドルを作成する前に`cudaSetDevice`を使用して異なるデバイスを異なるホストスレッドに関連付け、それぞれのホストスレッドで一意のcuDNNハンドルを作成し、後続のライブラリ呼び出しをそのデバイスに関連付けることができます。この場合、異なるハンドルで行われたcuDNNライブラリ呼び出しは自動的に異なるデバイスで実行されます。

特定のcuDNNコンテキストに関連付けられたデバイスは、対応する`cudnnCreate()`と`cudnnDestroy()`の呼び出し間で変更されないと想定されています。同じホストスレッド内で異なるデバイスを使用するためには、アプリケーションは`cudaSetDevice`を呼び出して使用する新しいデバイスを設定し、その後`cudnnCreate()`を呼び出して新しいデバイスに関連付けられた別のcuDNNコンテキストを作成する必要があります。

### テンソルとレイアウト

グラフAPIまたはレガシーAPIのどちらを使用する場合でも、cuDNN操作は入力としてテンソルを受け取り、出力としてテンソルを生成します。

#### テンソル記述子

cuDNNライブラリは、次のパラメーターで定義された一般的なn次元テンソル記述子を使用してデータを記述します。

- 3から8までの次元数
- データタイプ（32ビット浮動小数点、64ビット浮動小数点、16ビット浮動小数点など）
- 各次元のサイズを定義する整数配列
- 各次元のストライドを定義する整数配列（例えば、同じ次元から次の要素に到達するために追加する要素数）

このテンソル定義により、例えば、次元と次元の積および次の次元のストライドの積よりも小さいストライドを持つことで、同じテンソル内でいくつかの次元が重複することができます。cuDNNでは、特に指定がない限り、すべてのルーチンは順伝播入力テンソルの重複次元をサポートしますが、出力テンソルの次元は重複できません。このテンソル形式は負のストライドをサポートします（データのミラーリングに役立つことがあります）が、cuDNNルーチンは、特に指定がない限り、負のストライドを持つテンソルをサポートしません。

#### WXYZテンソル記述子

テンソル記述子の形式は頭字語を使用して識別され、各文字は対応する次元を参照します。

- すべてのストライドは厳密に正です。
- 文字で参照される次元は、それぞれのストライドの降順に並べられています。

#### 3次元テンソル記述子

3次元テンソルは、行列乗算に一般的に使用され、3つの文字：B、M、Nで表されます。Bはバッチサイズ（バッチMatMul用）、Mは行数、Nは列数を表します。詳細については、`CUDNN_BACKEND_OPERATION_MATMUL_DESCRIPTOR`操作を参照してください。

#### 4次元テンソル記述子

4次元テンソル記述子は、バッチサイズ、特徴マップの数、高さ、幅をそれぞれ表す4つの文字：N、C、H、Wで、2D画像のバッチの形式を定義するために使用されます。文字はストライドの降順に並べられています。一般的に使用される4次元テンソル形式は次のとおりです。

- NCHW
- NHWC
- CHWN

#### 5次元テンソル記述子

5次元テンソル記述子は、バッチサイズ、特徴マップの数、深さ、高さ、幅をそれぞれ表す5つの文字：N、C、D、H、Wで、3D画像のバッチの形式を定義するために使用されます。文字はストライドの降順に並べられています。一般的に使用される5次元テンソル形式は次のとおりです：

- NCDHW
- NDHWC
- CDHWN

#### 完全パックされたテンソル

テンソルがXYZ-fully-packedと定義されるのは、次の条件がすべて満たされる場合のみです：

- テンソルの次元数がfully-packed接尾辞に先行する文字の数に等しい。
- i番目の次元のストライドが(i+1)番目の次元の積と(i+1)番目のストライドに等しい。
- 最後の次元のストライドが1である。

#### 部分的にパックされたテンソル

部分的XYZパックされた用語は、部分的にパックされたテンソルを定義するために使用される文字のスーパーセットで説明されたテンソル形式の文脈でのみ適用されます。WXYZテンソルは次の条件がすべて満たされる場合にのみXYZパックされたと定義されます。

- -packed接尾辞で参照されないすべての次元のストライドが、次の次元の積と次のストライド以上である。
- -packed接尾辞で参照される各次元のストライドは、位置iで(i+1)番目の次元の積と(i+1)番目のストライドに等しい。
- 最後のテンソルの次元が-packed接尾辞に含まれる場合、そのストライドは1である。

例えば、NHWCテンソルがWCパックされている場合、c_strideは1に等しく、w_strideはc_dim x c_strideに等しいことを意味します。実際には、-packed接尾辞は通常テンソルのマイナー次元に適用されますが、主要次元のみに適用されることもあります。例えば、NCHWテンソルがNパックされている場合などです。

#### 空間的にパックされたテンソル

空間的にパックされたテンソルは、空間次元で部分的にパックされたものとして定義されます。例えば、空間的にパックされた4次元テンソルは、NCHW HWパックまたはCNHW HWパックのいずれかであることを意味します。

#### 重複するテンソル

テンソルは、次元の全範囲を反復すると同じアドレスが複数回生成される場合に重複していると定義されます。実際には、重複しているテンソルは、次元iの間隔が次元iの積と次の次元のストライドよりも小さい[i-1, nbDims]のいくつかのiに対して、stride[i-1] < stride[i]*dim[i]を持つことがあります。

### データレイアウト形式

このセクションでは、cuDNNテンソルがいくつかのデータレイアウト形式に従ってメモリに配置される方法について説明します。

テンソルのレイアウト形式を指定する推奨方法は、そのストライドを設定することです。v7 APIとの互換性のために、レイアウト形式のサブセットは`cudnnTensorFormat_t`列挙型を通じて設定することもできます。この列挙型はレガシーの理由でのみ提供されており、非推奨です。

#### テンソルの例

次の寸法を持つ画像のバッチを考えます：

- Nはバッチサイズです。1
- Cは特徴マップの数（つまりチャネル数）です。64
- Hは画像の高さです。5
- Wは画像の幅です。4

例を簡単にするために、画像のピクセル要素は0、1、2、3などの整数のシーケンスとして表現されています。

例：N=1、C=64、H=5、W=4の場合

次のサブセクションでは、この例を使用して異なるレイアウト形式を示します。

#### 畳み込みレイアウト

cuDNNは、次のセクションで説明するいくつかの畳み込みレイアウトをサポートしています。

##### NCHWメモリレイアウト

上記の4次元テンソルは、次のようにNCHW形式でメモリに配置されます。

- 最初のチャネル（c=0）から始めて、要素は行優先順序で連続して配置されます。
- 次に、2番目およびそれ以降のチャネルに進み、すべてのチャネルの要素が配置されるまで続けます。
- 次のバッチに進みます（Nが1より大きい場合）。

##### NHWCメモリレイアウト

NHWCメモリレイアウトの場合、対応する要素はすべてのCチャネルで最初に配置されます。次のように：

- チャネル0の最初の要素から始めて、次にチャネル1の最初の要素に進み、この順序で続けて、すべてのCチャネルの最初の要素が配置されます。
- 次に、チャネル0の2番目の要素を選択し、次にチャネル1の2番目の要素に進み、この順序で続けて、すべてのチャネルの2番目の要素が配置されます。
- チャネル0の行優先順序に従い、すべての要素を完了します。
- 次のバッチに進みます（Nが1より大きい場合）。

##### NC/32HW32メモリレイアウト

NC/32HW32は、NHWCに似ていますが、重要な違いがあります。NC/32HW32メモリレイアウトでは、64チャネルがそれぞれ32チャネルの2つのグループにグループ化されます。最初のグループはチャネルc0からc31までを含み、2番目のグループはチャネルc32からc63までを含みます。その後、各グループはNHWC形式を使用して配置されます。

##### 一般化されたNC/xHWxレイアウト形式については、次の観察が適用されます：

- チャネル次元Cのみがxチャネルごとにグループ化されます。
- x = 1の場合、各グループには1つのチャネルしかありません。したがって、1つのチャネル（つまり1つのグループ）の要素は連続して（行優先順序で）配置され、次のグループ（つまり次のチャネル）に進みます。これはNCHW形式と同じです。
- x = Cの場合、NC/xHWxはNHWCと同じであり、チャネル深度C全体が1つのグループとして考慮されます。x = Cの場合、次元C全体を1つの大きなベクトルとしてベクトル化し、C全体を配置し、その後残りの次元を配置することと考えられます。

`cudnnTensorFormat_t`のテンソル形式は、次のように解釈することもできます。NCHW INT8x32形式は、実際にはN x (C/32) x H x W x 32（各Wのための32 C）であり、NCHW INT8x4形式はN x (C/4) x H x W x 4（各Wのための4 C）です。したがって、VECT_Cという名前が付けられています。各WはCのベクトル（4または32）です。

##### MatMulレイアウト

3次元テンソル記述子で説明したように、matmulはBMN次元を使用する3Dテンソルを使用します。レイアウトは次のストライドを通じて指定できます。次に、推奨されるレイアウトの2つの例を示します：

- パックされた行優先順序：次元[B, M, N]、ストライド[MN, N, 1]、または
- パックされた列優先順序：次元[B, M, N]、ストライド[MN, 1, M]

3Dテンソルのアンパックされたレイアウトもサポートされていますが、そのサポート範囲はより不規則です。

### テンソルコア操作

cuDNN v7ライブラリは、サポートされているGPU SMバージョンでテンソルコアハードウェアを使用して計算集約的なルーチンを加速する機能を導入しました。テンソルコア操作は、NVIDIA Volta GPU以降でサポートされています。

テンソルコア操作は行列数学操作を加速します。cuDNNはFP16、FP32、およびINT32値に蓄積するテンソルコア操作を使用します。`cudnnMathType_t`列挙型を使用して`CUDNN_TENSOR_OP_MATH`に数学モードを設定すると、ライブラリがテンソルコア操作を使用することを示します。この列挙型は、テンソルコアを有効にするためのオプションを指定し、ルーチンごとに適用される必要があります。

デフォルトの数学モードは`CUDNN_DEFAULT_MATH`であり、テンソルコア操作をライブラリによって避けることを示します。`CUDNN_TENSOR_OP_MATH`モードはテンソルコアを使用するため、これらの2つのモードは浮動小数点操作の異なる順序のためにわずかに異なる数値結果を生成する可能性があります。

例えば、テンソルコア操作を使用して2つの行列を乗算した結果は非常に近いですが、常に同一ではありません。スカラー浮動小数点操作のシーケンスを使用して達成される結果と同じではありません。このため、cuDNNライブラリはテンソルコア操作を有効にする前にユーザーの明示的なオプトインを要求します。

ただし、一般的なディープラーニングモデルのトレーニングでの実験では、最終的なネットワークの精度と収束までの反復回数の両方で、テンソルコア操作とスカラー浮動小数点パスの間の差は無視できることが示されています。そのため、cuDNNライブラリは両方の動作モードを機能的に区別せず、テンソルコア操作が不適切な場合にスカラー経路が正当なフォールバックとして機能することを許可しています。

#### テンソルコア操作を使用するカーネル

- 畳み込み
- RNN
- マルチヘッドアテンション

詳細については、NVIDIAの混合精度でのトレーニングを参照してください。

#### ディープラーニングコンパイラのための主なガイドライン

- 畳み込み操作がテンソルコアに適していることを確認するために、大きなパディングと大きなフィルタの組み合わせを避けます。
- 入力とフィルタをNHWCに変換し、チャネルとバッチサイズを8の倍数に事前パディングします。
- ユーザー提供のテンソル、ワークスペース、および予約スペースが128ビット境界に揃っていることを確認します。1024ビットアライメントは、より良いパフォーマンスを提供することができます。

#### テンソルコアの精度に関する注記

FP16データの場合、テンソルコアはFP16入力で動作し、FP16出力を行い、FP16またはFP32で蓄積される可能性があります。FP16乗算は完全精度の結果をもたらし、m x n x k次元を持つ行列のドット積の他の積と共にFP32操作で蓄積されます。

FP32蓄積、FP16出力の場合、アキュムレータの出力はFP16にダウンコンバートされます。一般に、蓄積タイプは出力タイプと同等かそれ以上の精度です。
